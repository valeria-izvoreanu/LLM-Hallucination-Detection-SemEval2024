{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13959585,"sourceType":"datasetVersion","datasetId":8898369}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"f189e03a","cell_type":"markdown","source":"\n# Catboost SHROOM 2024 — Model-Aware\n","metadata":{}},{"id":"473d9c39","cell_type":"markdown","source":"## Installs & Imports","metadata":{}},{"id":"a34f2b56-ebff-4f85-a983-e6ae4b2d8515","cell_type":"code","source":"%pip -q install bert-score","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"96dc3c62","cell_type":"code","source":"import os, re, json, random\nimport numpy as np\nimport pandas as pd\nfrom collections import Counter\nfrom tqdm import tqdm\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import f1_score, accuracy_score\nfrom scipy.stats import spearmanr\nfrom sklearn.calibration import IsotonicRegression\nfrom sklearn.linear_model import Ridge\nfrom catboost import CatBoostClassifier, CatBoostRegressor, Pool\nimport joblib\n\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom scipy.stats import spearmanr\n\nimport torch\nfrom sentence_transformers import SentenceTransformer\nfrom bert_score import score as bertscore_score\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\nimport transformers\n\nSBERT_NAME    = \"sentence-transformers/all-MiniLM-L6-v2\"\nNLI_MODEL     = \"roberta-large-mnli\"\n\nRANDOM_SEED = 42\nN_FOLDS = 5\nOUT_DIR = \"artifacts_upgrade_complete\"\nos.makedirs(OUT_DIR, exist_ok=True)\n\nrandom.seed(RANDOM_SEED)\nnp.random.seed(RANDOM_SEED)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c98fba21","cell_type":"markdown","source":"## Data reading ","metadata":{}},{"id":"292d7d2d","cell_type":"code","source":"file_path = \"/kaggle/input/shroom-aware/\"\npath_val_model_aware = file_path + \"val.model-aware.v2.json\"\npath_test_model_aware = file_path + \"test.model-aware.json\"\n\ndef load_data(path):\n    with open(path, \"r\") as f:\n        data = json.load(f)  \n    return pd.DataFrame(data)\n\nval_df = load_data(path_val_model_aware)\n\ntest_df = load_data(path_test_model_aware)\n\n\nlabel_mapping = {'Hallucination': 1, 'Not Hallucination': 0}\n\ny_train = val_df['label'].map(label_mapping)\ny_test = test_df['label'].map(label_mapping)\n\nlabel_mapping = {'Hallucination': 1, 'Not Hallucination': 0}\nval_df['label'] = val_df['label'].astype(str).str.strip().str.title()\nval_df['label_num'] = val_df['label'].map(label_mapping)\n\nsource_df = val_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T07:38:03.720497Z","iopub.execute_input":"2025-12-05T07:38:03.721157Z","iopub.status.idle":"2025-12-05T07:38:03.773137Z","shell.execute_reply.started":"2025-12-05T07:38:03.721135Z","shell.execute_reply":"2025-12-05T07:38:03.772387Z"}},"outputs":[],"execution_count":3},{"id":"8f156f43","cell_type":"markdown","source":"## Feature extraction","metadata":{}},{"id":"f417985a-5405-4ac0-add3-976b4fb6153c","cell_type":"code","source":"sbert_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n\n_nli_tok = AutoTokenizer.from_pretrained(\"roberta-large-mnli\")\n_nli_model = AutoModelForSequenceClassification.from_pretrained(\"roberta-large-mnli\").to(device)\n_nli_model.eval()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f3bc98ad","cell_type":"code","source":"transformers.logging.set_verbosity_error()\n\n\ndef compute_bleu(reference, hypothesis):\n    ref_tokens = [reference.split()]\n    hyp_tokens = hypothesis.split()\n    smoothing = SmoothingFunction().method4\n    return sentence_bleu(ref_tokens, hyp_tokens, smoothing_function=smoothing)\n\ndef extract_nli_logits(premise, hypothesis):\n    inputs = _nli_tok(premise, hypothesis, return_tensors='pt', truncation=True, max_length=512)\n    inputs = {k: v.to(device) for k, v in inputs.items()}\n    with torch.no_grad():\n        outputs = _nli_model(**inputs)\n    logits = outputs.logits.squeeze().detach().cpu().numpy()\n    return logits\n\ndef extract_features(df, is_test=False, batch_size=16):\n\n    rows = []\n    srcs = df[\"src\"].astype(str).tolist()\n    tgts = df[\"tgt\"].astype(str).tolist()\n    hyps = df[\"hyp\"].astype(str).tolist()\n    n = len(df)\n\n    def lexical_feats(src, hyp):\n        s_tok, h_tok = src.split(), hyp.split()\n        len_src, len_hyp = len(s_tok), len(h_tok)\n        overlap = len(set(s_tok) & set(h_tok)) / (len(set(h_tok)) + 1e-6)\n        return len_src, len_hyp, overlap, (len_hyp + 1e-6) / (len_src + 1e-6)\n\n    lex_data = [lexical_feats(srcs[i], hyps[i]) for i in range(n)]\n    lex_df = pd.DataFrame(lex_data, columns=[\"len_src\", \"len_hyp\", \"overlap_ratio\", \"len_ratio\"])\n\n    sbert_cosines = np.full(n, np.nan)\n    \n    for i in tqdm(range(0, n, batch_size), desc=\"SBERT batches\"):\n        s = sbert_model.encode(srcs[i:i+batch_size], normalize_embeddings=True)\n        h = sbert_model.encode(hyps[i:i+batch_size], normalize_embeddings=True)\n        sbert_cosines[i:i+batch_size] = np.sum(s * h, axis=1)\n\n    entail, neutral, contra = np.full(n, np.nan), np.full(n, np.nan), np.full(n, np.nan)\n    _nli_model.eval()\n    for i in tqdm(range(0, n, batch_size), desc=\"NLI batches\"):\n        batch_prem = tgts[i:i+batch_size]\n        batch_hyp = hyps[i:i+batch_size]\n        enc = _nli_tok(batch_prem, batch_hyp, return_tensors=\"pt\", padding=True, truncation=True, max_length=256)\n        enc = {k: v.to(device) for k, v in enc.items()}\n        # Extract the raw model logits\n        with torch.no_grad():\n            logits = _nli_model(**enc).logits.detach().cpu().numpy()\n        entail[i:i+batch_size] = logits[:, 2]\n        neutral[i:i+batch_size] = logits[:, 1]\n        contra[i:i+batch_size] = logits[:, 0]\n\n    bertscores = np.full(n, np.nan)\n\n    P, R, F = bertscore_score(hyps, srcs, lang=\"en\", verbose=False, batch_size=batch_size)\n    bertscores = F.numpy()\n\n    features = pd.concat([lex_df], axis=1)\n    features[\"sbert_cosine\"] = sbert_cosines\n    features[\"bertscore_F1\"] = bertscores\n    features[\"entailment_logit\"] = entail\n    features[\"neutral_logit\"] = neutral\n    features[\"contradiction_logit\"] = contra\n    features[\"nli_margin\"] = entail - contra\n\n    features[\"tgt_len\"] = df[\"tgt\"].apply(lambda x: len(str(x).split()))\n    features[\"task\"] = df.get(\"task\", \"unknown_task\")\n    features[\"model_id\"] = df.get(\"model\", \"unknown_model\")\n\n    return features\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T07:38:26.716372Z","iopub.execute_input":"2025-12-05T07:38:26.716670Z","iopub.status.idle":"2025-12-05T07:38:26.732395Z","shell.execute_reply.started":"2025-12-05T07:38:26.716646Z","shell.execute_reply":"2025-12-05T07:38:26.731434Z"}},"outputs":[],"execution_count":6},{"id":"7ef327c0","cell_type":"markdown","source":"## Build matrices","metadata":{}},{"id":"bceedef2-7a6c-470a-b48f-d4833aa19819","cell_type":"code","source":"X_all = extract_features(source_df)\ny_all = source_df[\"label_num\"].astype(int).values","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"55f98ced","cell_type":"code","source":"cat_features = []\nfor c in [\"task\",\"model_id\"]:\n    if c in X_all.columns:\n        cat_features.append(X_all.columns.get_loc(c))\n\nprint(\"X shape:\", X_all.shape, \"| y shape:\", y_all.shape, \"| cat_features:\", cat_features)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T07:39:04.185348Z","iopub.execute_input":"2025-12-05T07:39:04.185619Z","iopub.status.idle":"2025-12-05T07:39:04.190218Z","shell.execute_reply.started":"2025-12-05T07:39:04.185599Z","shell.execute_reply":"2025-12-05T07:39:04.189583Z"}},"outputs":[{"name":"stdout","text":"X shape: (501, 13) | y shape: (501,) | cat_features: [11, 12]\n","output_type":"stream"}],"execution_count":8},{"id":"ca9cbac0","cell_type":"markdown","source":"## Catboost","metadata":{}},{"id":"cd369dfc-c3cb-4e59-be67-44dce162147d","cell_type":"code","source":"skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_SEED)\n\noof_score = np.zeros(len(X_all), dtype=float)\nfold_metrics = []\n\nfor fold, (tr, va) in enumerate(skf.split(X_all, y_all), 1):\n\n    X_tr, X_va = X_all.iloc[tr], X_all.iloc[va]\n    y_tr, y_va = y_all[tr], y_all[va]\n\n    train_pool = Pool(X_tr, y_tr, cat_features=cat_features if cat_features else None)\n    valid_pool = Pool(X_va, y_va, cat_features=cat_features if cat_features else None)\n\n    model = CatBoostClassifier(\n        loss_function=\"Logloss\",\n        depth=8, learning_rate=0.05, l2_leaf_reg=6.0,\n        iterations=2000, random_seed=RANDOM_SEED,\n        eval_metric=\"AUC\", verbose=False,\n        od_type=\"Iter\", od_wait=200\n    )\n\n    model.fit(train_pool, eval_set=valid_pool, use_best_model=True)\n\n    # Store out-of-fold probability scores\n    oof_score[va] = model.predict_proba(X_va)[:, 1]\n\n    # Find best threshold for this fold\n    best_f1, best_thr = 0, 0.5\n    for thr in np.linspace(0.05, 0.95, 19):\n        f1 = f1_score(y_va, (oof_score[va] >= thr).astype(int), average=\"macro\")\n        if f1 > best_f1:\n            best_f1, best_thr = f1, thr\n\n    fold_metrics.append({\n        \"fold\": fold,\n        \"f1_macro\": best_f1,\n        \"thr\": best_thr\n    })\n\n    model.save_model(os.path.join(OUT_DIR, f\"unified_model_fold{fold}.cbm\"))\n\npd.DataFrame(fold_metrics)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T07:53:33.421900Z","iopub.execute_input":"2025-12-05T07:53:33.422616Z","iopub.status.idle":"2025-12-05T07:53:41.597795Z","shell.execute_reply.started":"2025-12-05T07:53:33.422590Z","shell.execute_reply":"2025-12-05T07:53:41.597057Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"   fold  f1_macro   thr\n0     1  0.676022  0.40\n1     2  0.865131  0.45\n2     3  0.739583  0.65\n3     4  0.767673  0.65\n4     5  0.761386  0.50","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fold</th>\n      <th>f1_macro</th>\n      <th>thr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.676022</td>\n      <td>0.40</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.865131</td>\n      <td>0.45</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.739583</td>\n      <td>0.65</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.767673</td>\n      <td>0.65</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.761386</td>\n      <td>0.50</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":32},{"id":"8d045651-41d9-480a-b32d-e961b20a6732","cell_type":"code","source":"def predict_unified(df, threshold=None):\n    X_te = extract_features(df, is_test=True)\n\n    preds = np.zeros(len(X_te))\n\n    # Average predictions from all saved folds\n    for fold in range(1, N_FOLDS + 1):\n        model = CatBoostClassifier()\n        model.load_model(os.path.join(OUT_DIR, f\"unified_model_fold{fold}.cbm\"))\n        preds += model.predict_proba(X_te)[:, 1] / N_FOLDS\n\n    if threshold is not None:\n        yhat = (preds >= threshold).astype(int)\n    else:\n        yhat = None\n\n    return pd.DataFrame({\n        \"id\": X_te.get(\"id\", pd.Series(range(len(X_te)))),\n        \"score\": preds,\n        \"pred\": yhat\n    })\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:01:50.040385Z","iopub.execute_input":"2025-12-05T08:01:50.041002Z","iopub.status.idle":"2025-12-05T08:01:50.046301Z","shell.execute_reply.started":"2025-12-05T08:01:50.040976Z","shell.execute_reply":"2025-12-05T08:01:50.045560Z"}},"outputs":[],"execution_count":40},{"id":"c15f1eca-956c-4f29-845a-1dd50a0ec78c","cell_type":"code","source":"best_global_thr = 0.5\nbest_global_f1 = 0\n\nfor thr in np.linspace(0.05, 0.95, 19):\n    f1 = f1_score(y_all, (oof_score >= thr).astype(int), average=\"macro\")\n    if f1 > best_global_f1:\n        best_global_f1, best_global_thr = f1, thr\n\nprint(\"Best threshold:\", best_global_thr)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:01:51.964093Z","iopub.execute_input":"2025-12-05T08:01:51.964619Z","iopub.status.idle":"2025-12-05T08:01:51.991507Z","shell.execute_reply.started":"2025-12-05T08:01:51.964596Z","shell.execute_reply":"2025-12-05T08:01:51.990716Z"}},"outputs":[{"name":"stdout","text":"Best threshold: 0.49999999999999994\n","output_type":"stream"}],"execution_count":41},{"id":"e606aa4c-ee65-41c0-82cb-2c1451b49666","cell_type":"code","source":"sub = predict_unified(test_df, threshold=best_global_thr)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:01:54.169341Z","iopub.execute_input":"2025-12-05T08:01:54.170079Z","iopub.status.idle":"2025-12-05T08:03:33.616250Z","shell.execute_reply.started":"2025-12-05T08:01:54.170027Z","shell.execute_reply":"2025-12-05T08:03:33.615639Z"}},"outputs":[{"name":"stderr","text":"SBERT batches: 100%|██████████| 94/94 [00:02<00:00, 36.55it/s]\nNLI batches: 100%|██████████| 94/94 [00:21<00:00,  4.32it/s]\n","output_type":"stream"}],"execution_count":42},{"id":"97dc5510-545d-4bbf-8e5b-076a9d92fbed","cell_type":"code","source":"y_pred = sub[\"pred\"].astype(int).values\n\ny_score = sub[\"score\"].astype(float).values\n\n# Metrics\nf1 = f1_score(y_true, y_pred, average=\"macro\")\nacc = accuracy_score(y_true, y_pred)\nrho = spearmanr(y_true, y_score).correlation\n\nprint(f\"Macro F1      : {f1:.4f}\")\nprint(f\"Accuracy      : {acc:.4f}\")\nprint(f\"Spearman Rho  : {rho:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:03:33.617420Z","iopub.execute_input":"2025-12-05T08:03:33.617707Z","iopub.status.idle":"2025-12-05T08:03:33.627539Z","shell.execute_reply.started":"2025-12-05T08:03:33.617673Z","shell.execute_reply":"2025-12-05T08:03:33.626844Z"}},"outputs":[{"name":"stdout","text":"\n===== UNIFIED MODEL METRICS =====\nMacro F1      : 0.7379\nAccuracy      : 0.7633\nSpearman Rho  : 0.5328\n=================================\n\n","output_type":"stream"}],"execution_count":43},{"id":"ff608532-41e9-4aba-8735-049859eaa20c","cell_type":"code","source":"df_save = sub[[\"id\", \"score\"]].rename(columns={\"score\": \"catboost_prob\"})\ndf_save.to_csv(\"submission_catboost.csv\", index=False)\n\nprint(\"Saved prediction file:\")\nprint(df_save.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:03:33.628189Z","iopub.execute_input":"2025-12-05T08:03:33.628390Z","iopub.status.idle":"2025-12-05T08:03:33.640582Z","shell.execute_reply.started":"2025-12-05T08:03:33.628375Z","shell.execute_reply":"2025-12-05T08:03:33.639933Z"}},"outputs":[{"name":"stdout","text":"Saved prediction file:\n   id  catboost_prob\n0   0       0.353216\n1   1       0.326115\n2   2       0.536144\n3   3       0.606929\n4   4       0.307855\n","output_type":"stream"}],"execution_count":44}]}