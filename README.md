# ðŸ•µLLM Hallucination Detection (SemEval-2024 Task 6)

![NLP](https://img.shields.io/badge/Task-Hallucination%20Detection-red)
![Model](https://img.shields.io/badge/Model-Mistral%20%2B%20DeBERTa-blue)
![Method](https://img.shields.io/badge/Method-Semi--Supervised-green)

## Overview
This project targets **SemEval-2024 Task 6 (SHROOM)**: detecting fluent but factually incorrect ("hallucinated") text generated by LLMs.
The core challenge was working with **Unlabeled Data**. I developed a **Teacher-Student framework** using Mistral-7B to generate pseudo-labels, which were then used to train a robust ensemble of DeBERTa and CatBoost.

## ðŸš€ Key Techniques
*   **Pseudo-Labeling (Semi-Supervised):** Used **Mistral-7B** via zero-shot prompting to create synthetic labels for the training set.
*   **Hybrid Ensemble:** Combined a Deep Learning approach (mDeBERTa-v3) with a Feature-Based approach (CatBoost with lexical overlap features).
*   **Confidence Filtering:** Implemented a thresholding logic to only train on "High Confidence" pseudo-labels, reducing noise.

##  Project Structure
| Notebook | Function |
| :--- | :--- |
| `01_Exploration...` | **The Teacher:** EDA and using Mistral-7B to generate initial pseudo-labels. |
| `02_Feature_Eng...` | **The Feature Model:** Engineering lexical features (SBERT similarity, Overlap) and training CatBoost. |
| `03_DeBERTa...` | **The Student & Ensemble:** Fine-tuning mDeBERTa on filtered labels and stacking it with CatBoost for the final prediction. |
